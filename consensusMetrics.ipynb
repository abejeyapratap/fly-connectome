{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netneurotools import cluster\n",
    "from netneurotools import modularity\n",
    "\n",
    "from sknetwork.clustering import Louvain, get_modularity\n",
    "from sknetwork.data import from_edge_list\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNp01 (giant fiber) to DNp11\n",
    "body_ids = [\"2307027729\",\"5813024015\", \"1565846637\", \"1405231475\", \"1466998977\", \"5813023322\", \"1100404581\", \"1226887763\", \"1228264951\", \"512851433\", \"5813026936\", \"1281324958\"]\n",
    "DNp_ids = [int(i) for i in body_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensusResults = np.load(\"consensusResults.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_mat = np.loadtxt(\"adj_mat.csv\", delimiter=\",\")\n",
    "all_connection_df = pd.read_csv(\"all_connection_df.csv\")\n",
    "dfFilt = all_connection_df[['bodyId_pre', 'bodyId_post', 'weight']] # sknetwork uses 3rd col as weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sknetwork: only needed bc Louvain's clustering assignment output is based on graph.names order\n",
    "graph = from_edge_list(list(dfFilt.itertuples(index=False)), weighted=True, directed=True) # without directed=True, wrong # of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<5596x5596 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 389065 stored elements in Compressed Sparse Row format>,\n",
       " array([ 326253554,  357245785,  357249472, ..., 7112615304, 7112622763,\n",
       "        7112624834]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.adjacency, graph.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directed, weighted networkx graph from dataframe of edges & weights\n",
    "# NOTE: it seems that NetworkX conversion shuffles edge ordering (so clustering results may be different)\n",
    "G = nx.from_pandas_edgelist(all_connection_df, 'bodyId_pre', 'bodyId_post', 'weight', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5596, 389065)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# cluster_betweenness = nx.betweenness_centrality(cluster_subgraph, weight='weight') # maybe set endpoints=True\n",
    "# cluster_degreeCentrality = nx.degree_centrality(cluster_subgraph)\n",
    "# cluster_eigenCentrality = nx.eigenvector_centrality(cluster_subgraph, weight='weight')\n",
    "# degAssortCoeff = nx.degree_assortativity_coefficient(cluster_subgraph, weight='weight')\n",
    "# avgDegCon = nx.average_degree_connectivity(cluster_subgraph, weight='weight')\n",
    "# groupBetCentrality = nx.group_betweenness_centrality(G, cluster_nodes, weight='weight')\n",
    "# groupDegreeCentrality = nx.group_degree_centrality(G, cluster_nodes)\n",
    "\n",
    "# smallWorld = nx.algorithms.smallworld.sigma(cluster_subgraph.to_undirected())\n",
    "\n",
    "# cluster_modularity = nx.community.modularity(G, cluster_nodes, weight='weight')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each consensus result, for each cluster, extract its subgraph\n",
    "# calculate graph theory metrics (degree centrality, betweenness centrality, small worldness) for each subgraph\n",
    "# maybe calculate modularity (reflects degree of community structure) and assortativity (reflects tendency of nodes to connect to similar nodes)\n",
    "\n",
    "# data structure to store results: dictionary of list containing a dictionary of networkx's values\n",
    "# {consensusIterationNum: [{cluster1's metric}, {cluster2's metric}] }\n",
    "\n",
    "metricName = \"degreeCentrality\"\n",
    "graphMetric = {}\n",
    "\n",
    "for result in consensusResults:\n",
    "    iteration, consensus = result\n",
    "    graphMetric[iteration] = []\n",
    "    \n",
    "    for clusterId in range(1, consensus.max()+1): # cluster indices are beween 1-n (inclusive)\n",
    "        cluster_indices = np.where(consensus == clusterId)[0]\n",
    "        cluster_nodes = [graph.names[i] for i in cluster_indices] # bodyIds\n",
    "        cluster_subgraph = G.subgraph(cluster_nodes)\n",
    "        # print(cluster_subgraph.number_of_nodes(), cluster_subgraph.number_of_edges())\n",
    "\n",
    "        # calculate graph theory metrics\n",
    "        cluster_degreeCentrality = nx.degree_centrality(cluster_subgraph)\n",
    "        graphMetric[iteration].append(cluster_degreeCentrality)\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph theory results\n",
    "with open(f'{metricName}.pkl', 'wb') as handle:\n",
    "    pickle.dump(graphMetric, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results\n",
    "with open(f'{metricName}.pkl', 'rb') as handle:\n",
    "    temp3 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07173788325575241"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cluster_degreeCentrality.values()) / len(cluster_degreeCentrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.482007996446024"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupDegreeCentrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145.67808078312498"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(avgDegCon.values())/len(avgDegCon.values()) # doesn't seem meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0840938857573405"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degAssortCoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008290702240462593"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cluster_eigenCentrality.values()) / len(cluster_eigenCentrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004125238268360178"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cluster_betweenness.values()) / len(cluster_betweenness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.036588253808819825, 0.045981048093354494)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_betweenness[2307027729], cluster_betweenness[5813024015] # DNp01,02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find subgraph consisting of nodes in cluster 1\n",
    "# first extract the nodes associated with cluster 1\n",
    "consensus250 = consensusResults[0][1] # consensus clustering labels of each of the 5596 nodes for iteration 250\n",
    "cluster1_nodeIndices = np.where(consensus250 == 4)[0] # indices of cluster1 neurons based on graph.names\n",
    "cluster1_nodes = [graph.names[i] for i in cluster1_nodeIndices] # get cluster1 neuron bodyIds from graph.names\n",
    "\n",
    "# then extract the subgraph\n",
    "cluster1_subgraph = G.subgraph(cluster1_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1094, 42890)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster1_subgraph.number_of_nodes(), cluster1_subgraph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find betweenness centrality of each node in subgraph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
