{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sknetwork.data import from_edge_list\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNp01 (giant fiber) to DNp11\n",
    "body_ids = [\"2307027729\",\"5813024015\", \"1565846637\", \"1405231475\", \"1466998977\", \"5813023322\", \"1100404581\", \"1226887763\", \"1228264951\", \"512851433\", \"5813026936\", \"1281324958\"]\n",
    "DNp_ids = [int(i) for i in body_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"./data/consensusResults2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensusResults = np.load(f\"{DIR}/consensusResults.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_mat = np.loadtxt(\"adj_mat.csv\", delimiter=\",\")\n",
    "all_connection_df = pd.read_csv(\"./data/all_connection_df.csv\")\n",
    "dfFilt = all_connection_df[['bodyId_pre', 'bodyId_post', 'weight']] # sknetwork uses 3rd col as weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sknetwork: only needed bc Louvain's clustering assignment output is based on graph.names order\n",
    "graph = from_edge_list(list(dfFilt.itertuples(index=False)), weighted=True, directed=True) # without directed=True, wrong # of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<5596x5596 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 389065 stored elements in Compressed Sparse Row format>,\n",
       " array([ 326253554,  357245785,  357249472, ..., 7112615304, 7112622763,\n",
       "        7112624834]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.adjacency, graph.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directed, weighted networkx graph from dataframe of edges & weights\n",
    "# NOTE: it seems that NetworkX conversion shuffles edge ordering (so clustering results may be different)\n",
    "G = nx.from_pandas_edgelist(all_connection_df, 'bodyId_pre', 'bodyId_post', 'weight', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5596, 389065)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes(), G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# cluster_betweenness = nx.betweenness_centrality(cluster_subgraph, weight='weight') # maybe set endpoints=True\\n# cluster_degreeCentrality = nx.degree_centrality(cluster_subgraph)\\n# cluster_eigenCentrality = nx.eigenvector_centrality(cluster_subgraph, weight='weight')\\n# degAssortCoeff = nx.degree_assortativity_coefficient(cluster_subgraph, weight='weight')\\n# avgDegCon = nx.average_degree_connectivity(cluster_subgraph, weight='weight')\\n\\n# groupBetCentrality = nx.group_betweenness_centrality(G, cluster_nodes, weight='weight')\\n# groupDegreeCentrality = nx.group_degree_centrality(G, cluster_nodes)\\n\\n# smallWorld = nx.algorithms.smallworld.sigma(cluster_subgraph.to_undirected())\\n\\n# cluster_modularity = nx.community.modularity(G, cluster_nodes, weight='weight')\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# cluster_betweenness = nx.betweenness_centrality(cluster_subgraph, weight='weight') # maybe set endpoints=True\n",
    "# cluster_degreeCentrality = nx.degree_centrality(cluster_subgraph)\n",
    "# cluster_eigenCentrality = nx.eigenvector_centrality(cluster_subgraph, weight='weight')\n",
    "# degAssortCoeff = nx.degree_assortativity_coefficient(cluster_subgraph, weight='weight')\n",
    "# avgDegCon = nx.average_degree_connectivity(cluster_subgraph, weight='weight')\n",
    "\n",
    "# groupBetCentrality = nx.group_betweenness_centrality(G, cluster_nodes, weight='weight')\n",
    "# groupDegreeCentrality = nx.group_degree_centrality(G, cluster_nodes)\n",
    "\n",
    "# smallWorld = nx.algorithms.smallworld.sigma(cluster_subgraph.to_undirected())\n",
    "\n",
    "# cluster_modularity = nx.community.modularity(G, cluster_nodes, weight='weight')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating graph theory metrics: degreeCentrality\n",
      "\n",
      "Iteration 10 runtime: 0.55s\n",
      "Iteration 25 runtime: 0.44s\n",
      "Iteration 50 runtime: 0.43s\n",
      "Iteration 75 runtime: 0.43s\n",
      "Iteration 100 runtime: 0.43s\n",
      "Iteration 150 runtime: 0.48s\n",
      "Iteration 200 runtime: 0.51s\n",
      "Iteration 250 runtime: 0.43s\n",
      "Iteration 300 runtime: 0.43s\n",
      "Iteration 350 runtime: 0.43s\n",
      "Iteration 400 runtime: 0.42s\n",
      "Iteration 450 runtime: 0.42s\n",
      "Iteration 500 runtime: 0.43s\n",
      "Total runtime: 5.82s\n"
     ]
    }
   ],
   "source": [
    "# for each consensus result, for each cluster, extract its subgraph\n",
    "# calculate graph theory metrics (degree centrality, betweenness centrality, small worldness) for each subgraph\n",
    "# maybe calculate modularity (reflects degree of community structure) and assortativity (reflects tendency of nodes to connect to similar nodes)\n",
    "\n",
    "# data structure to store results: dictionary of list containing a dictionary of networkx's values\n",
    "'''\n",
    "{\n",
    "    consensusIterationNum: [\n",
    "        {cluster1's metric}, \n",
    "        {cluster2's metric}, \n",
    "        ...\n",
    "        ],\n",
    "     consensusIterationNum: [\n",
    "        {cluster1's metric}, \n",
    "        {cluster2's metric}, \n",
    "        ...\n",
    "        ]\n",
    "}\n",
    "'''\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "metricName = \"degreeCentrality\" # CHANGE THIS\n",
    "graphMetric = {}\n",
    "\n",
    "print(f\"Calculating graph theory metrics: {metricName}\\n\")\n",
    "for result in consensusResults:\n",
    "    iteration, consensus = result\n",
    "    graphMetric[iteration] = []\n",
    "    \n",
    "    iterStartTime = time.time()\n",
    "    for clusterId in range(1, consensus.max()+1): # cluster indices are beween 1-n (inclusive)\n",
    "        cluster_indices = np.where(consensus == clusterId)[0]\n",
    "        cluster_nodes = [graph.names[i] for i in cluster_indices] # bodyIds\n",
    "        cluster_subgraph = G.subgraph(cluster_nodes)\n",
    "        # print(cluster_subgraph.number_of_nodes(), cluster_subgraph.number_of_edges())\n",
    "\n",
    "        ### calculate graph theory metrics - uncomment as needed ###\n",
    "        # Degree Centrality\n",
    "        cluster_degreeCentrality = nx.degree_centrality(cluster_subgraph)\n",
    "        graphMetric[iteration].append(cluster_degreeCentrality)\n",
    "\n",
    "        # Betweenness Centrality\n",
    "        # cluster_betweenness = nx.betweenness_centrality(cluster_subgraph, weight='weight') # maybe set endpoints=True\n",
    "        # graphMetric[iteration].append(cluster_betweenness)\n",
    "\n",
    "        # Small Worldness (sigma)\n",
    "        # smallWorld = nx.algorithms.smallworld.sigma(cluster_subgraph.to_undirected())\n",
    "        # graphMetric[iteration].append(smallWorld)\n",
    "\n",
    "        # Eigenvector Centrality\n",
    "        # cluster_eigenvector = nx.eigenvector_centrality_numpy(cluster_subgraph, weight='weight') # numpy version is faster for larger graphs\n",
    "        # graphMetric[iteration].append(cluster_eigenvector)\n",
    "\n",
    "        # VoteRank\n",
    "        # if clusterId == 4:\n",
    "        #     cluster_voterank = nx.voterank(cluster_subgraph)\n",
    "    print(f\"Iteration {iteration} runtime: {(time.time()-iterStartTime):.2f}s\")\n",
    "    # print()\n",
    "\n",
    "print(f\"Total runtime: {(time.time()-startTime):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph theory results\n",
    "with open(f'{DIR}/{metricName}.pkl', 'wb') as handle:\n",
    "    pickle.dump(graphMetric, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results\n",
    "with open(f'{DIR}/{metricName}.pkl', 'rb') as handle:\n",
    "    temp = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07173788325575241"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cluster_degreeCentrality.values()) / len(cluster_degreeCentrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.482007996446024"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupDegreeCentrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145.67808078312498"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(avgDegCon.values())/len(avgDegCon.values()) # doesn't seem meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0840938857573405"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degAssortCoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008290702240462593"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cluster_eigenCentrality.values()) / len(cluster_eigenCentrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004125238268360178"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cluster_betweenness.values()) / len(cluster_betweenness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.036588253808819825, 0.045981048093354494)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_betweenness[2307027729], cluster_betweenness[5813024015] # DNp01,02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find subgraph consisting of nodes in cluster 1\n",
    "# first extract the nodes associated with cluster 1\n",
    "consensus250 = consensusResults[0][1] # consensus clustering labels of each of the 5596 nodes for iteration 250\n",
    "cluster1_nodeIndices = np.where(consensus250 == 4)[0] # indices of cluster1 neurons based on graph.names\n",
    "cluster1_nodes = [graph.names[i] for i in cluster1_nodeIndices] # get cluster1 neuron bodyIds from graph.names\n",
    "\n",
    "# then extract the subgraph\n",
    "cluster1_subgraph = G.subgraph(cluster1_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1094, 42890)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster1_subgraph.number_of_nodes(), cluster1_subgraph.number_of_edges()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
